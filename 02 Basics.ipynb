{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF:  1.1.0 \n",
      "Numpy:  1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TF: \", tf.__version__, \"\\nNumpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitive Data Types\n",
    "- DT_FLOAT\ttf.float32\t32 bits floating point.\n",
    "- DT_DOUBLE\ttf.float64\t64 bits floating point.\n",
    "- DT_INT8\ttf.int8\t8 bits signed integer.\n",
    "- DT_INT16\ttf.int16\t16 bits signed integer.\n",
    "- DT_INT32\ttf.int32\t32 bits signed integer.\n",
    "- DT_INT64\ttf.int64\t64 bits signed integer.\n",
    "- DT_UINT8\ttf.uint8\t8 bits unsigned integer.\n",
    "- DT_UINT16\ttf.uint16\t16 bits unsigned integer.\n",
    "- DT_STRING\ttf.string\tVariable length byte arrays. Each element of a Tensor is a byte array.\n",
    "- DT_BOOL\ttf.bool\tBoolean.\n",
    "- DT_COMPLEX64\ttf.complex64\tComplex number made of two 32 bits floating points: real and imaginary parts.\n",
    "- DT_COMPLEX128\ttf.complex128\tComplex number made of two 64 bits floating points: real and imaginary parts.\n",
    "- DT_QINT8\ttf.qint8\t8 bits signed integer used in quantized Ops.\n",
    "- DT_QINT32\ttf.qint32\t32 bits signed integer used in quantized Ops.\n",
    "- DT_QUINT8\ttf.quint8\t8 bits unsigned integer used in quantized Ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw:  Tensor(\"add_1:0\", shape=(), dtype=string)\n",
      "b'Hello World'\n"
     ]
    }
   ],
   "source": [
    "h = tf.constant(\"Hello \")\n",
    "w = tf.constant(\"World\")\n",
    "hw = h + w\n",
    "print(\"hw: \", hw)\n",
    "with tf.Session() as session:\n",
    "    ans = session.run(hw)\n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello World'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "session.run(hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:  -3\n",
      "<tensorflow.python.framework.ops.Graph object at 0x11c5738d0>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x11c4e6a58>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x11c4e6a58>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5, name = \"a\")\n",
    "b = tf.constant(4)\n",
    "c = tf.constant(3)\n",
    "\n",
    "d = tf.multiply(a, b)\n",
    "e = tf.add(c, d)\n",
    "f = tf.subtract(d, e)\n",
    "\n",
    "print(\"f: \", session.run(f))\n",
    "print(tf.Graph())\n",
    "print(tf.get_default_graph())\n",
    "print(f.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'a:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'Const_4:0' shape=() dtype=int32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b \n",
    "# The name of the Tensor object is simply the name of its corresponding operation \n",
    "# (concatenated with a colon), followed by the index of that tensor in the outputs of the \n",
    "# operation that produced it —it is possible to have more than one.\n",
    "# Objects residing within the same graph cannot have the same name\n",
    "# As a consequence, it will automatically add an underscore and a number to distinguish the two. \n",
    "# However, both objects can have the same name when they are associated with different graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "print(g1 is tf.get_default_graph())\n",
    "with g2.as_default():\n",
    "    print(g1 is tf.get_default_graph(), g2 is tf.get_default_graph())\n",
    "print(g1 is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = tf.Graph()\n",
    "g2 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    c1 = tf.constant(4.0)\n",
    "\n",
    "with g2.as_default():\n",
    "    c2 = tf.constant(2.0)\n",
    "\n",
    "#c = c1 + c2\n",
    "#session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor '3/Const:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group variable with name scope\n",
    "with tf.name_scope(\"3\"):\n",
    "    c1 = tf.constant(4.0)\n",
    "c1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 20, 23, -3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetchers = [a, b, c, d, e, f]\n",
    "session.run(fetchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_6:0' shape=(2, 3) dtype=int32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_7:0' shape=(2, 3) dtype=int64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant(4, dtype='float64')\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow operation\tDescription\n",
    "- tf.constant(value)\tCreates a tensor populated with values of as specified by arguments “value”\n",
    "- tf.fill(shape,value)\tCreates a tensor of shape “shape\" and fills it with “value\" \n",
    "- tf.zeros(shape)\tReturns a tensor of shape “shape” and all elements set to zero\n",
    "- tf.zeros_like(tensor)\tReturns a tensor of the same type and shape as “tensor\" with all elements set to zero\n",
    "- tf.ones(shape)\tReturns a tensor of shape “shape\" and all elements set to 1\n",
    "- tf.ones_like(tensor)\tReturns a tensor of the same type and shape as “tensor\" with all elements set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.ones((4, 3))\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.fill((4, 3), 1)\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow operation\t\n",
    "\n",
    "Description\n",
    "- tf.random_normal(shape, mean, stddev)\tOutputs random values from a normal distribution\n",
    "- tf.truncated_normal(shape, mean, stddev)\tOutputs random values from a truncated normal distribution (values whose  magnitude is more than 2 standard deviations from the mean are dropped and re-picked).\n",
    "- tf.random_uniform(shape, minval, maxval)\tGenerated values from a uniform distribution in the range [minval, maxval)\n",
    "- tf.random_shuffle(tensor)\tRandomly shuffles a tensor along its first dimension\n",
    "- tf.random_crop(tensor, shape)\tSlices a shape “shape” portion out of “tensor\" at a uniformly chosen offset\n",
    "- tf.multinomial(logits, n_samples)\tDraws samples from a multinomial distribution\n",
    "- tf.random_gamma(shape,alpha,beta)\tDraws “shape\" samples from each of the given Gamma distribution(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96174979,  0.44918132,  0.51270759],\n",
       "       [ 0.83489168,  0.54734325,  0.80996978],\n",
       "       [ 0.71889913,  0.39656377,  0.95373368],\n",
       "       [ 0.93378425,  0.04777336,  0.07103348]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.random_uniform((4, 3), seed=100)\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02630099, -0.07955143, -0.298599  ],\n",
       "       [ 0.17631671, -0.30626023,  0.12118966],\n",
       "       [ 0.14748672, -0.19404596, -0.03731908],\n",
       "       [ 0.08446319,  0.31936881,  0.66740936]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.random_normal((4, 3), mean=0, stddev=0.3, seed=100)\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.2       ,  0.22500001,  0.25      ,  0.27500001,  0.30000001], dtype=float32),)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.linspace(0.2, 0.3, 5)\n",
    "print(c.get_shape())\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.40000001,  0.64999998,  0.89999998,  1.14999998,  1.39999998,\n",
       "        1.64999998,  1.89999998,  2.1500001 ,  2.4000001 ,  2.6500001 ,\n",
       "        2.9000001 ,  3.1500001 ,  3.4000001 ,  3.6500001 ,  3.9000001 ,\n",
       "        4.1500001 ,  4.4000001 ,  4.6500001 ,  4.9000001 ], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.range(0.4, 5.0, 0.25)\n",
    "print(c.get_shape())\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9999913 ],\n",
       "       [ 0.14483425],\n",
       "       [ 0.99418771],\n",
       "       [ 0.55156505],\n",
       "       [ 0.99135911]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random_normal((5, 10), mean = 0.0, stddev = 1.0, seed = 0)\n",
    "w = tf.random_normal((10, 1), mean = 0.0, stddev = 1.0, seed = 0)\n",
    "b = tf.fill((5, 1), 1.0)\n",
    "s = tf.sigmoid(tf.matmul(X, w) - b)\n",
    "session.run(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow operator\tShortcut\tDescription\n",
    "- tf.add()\ta + b\tAdd a and b, element-wise\n",
    "- tf.mul()\ta * b\tMultiply a and b, element-wise\n",
    "- tf.sub()\ta - b\tSubtract a from b, element-wise\n",
    "- tf.div()\ta / b\tWill perform element-wise integer division when given an integer type tensor, and floatingpoint (“true”) division on floating point tensors\n",
    "- tf.pow()\ta ** b\tThe result of raising each element in a to its corresponding element b, element-wise\n",
    "- tf.mod()\ta % b\tElement-wise modulo\n",
    "- tf.logical_and()\ta & b\tReturns the truth table of a & b, element-wise. dtype must be tf.bool\n",
    "- tf.greater()\ta > b\tReturns the truth table of a > b, element-wise\n",
    "- tf.greater_equal()\ta >= b\tReturns the truth table of a >= b, element-wise\n",
    "- tf.less_equal()\ta <= b\tReturns the truth table of a <= b , element-wise\n",
    "- tf.less()\ta < b\tReturns the truth table of a < b, element-wise\n",
    "- tf.neg()\t-a\tReturns the negative value of each element in a\n",
    "- tf.logical_not()\t~a\tReturns the logical NOT of each element in a. Only compatible with Tensor objectswith dtype of - tf.bool\n",
    "- tf.abs()\tabs(a)\tReturns the absolute value of each element in a\n",
    "- tf.logical_or()\ta | b\tReturns the truth table of a | b, element-wise. dtype must be tf.bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable \n",
    "\n",
    "During the optimization process, tuning the weights of the model by iterative updates requires that their current state be maintained. For that purpose, TensorFlow uses special objects called “Variables”. Variables, unlike other Tensor objects that are “refilled” across calls to run(), can maintain a fixed state in the graph. Like other Tensors, Variables can be used as input for other operations in the graph.\n",
    "\n",
    "Using Variables is done in two stages: (1) we call the tf.Variable() function in order to create a Variable, and define what value it will be initialized with and (2) we then have to explicitly perform an initialization operation by running the session with the tf.initialize_all_variables() method, which allocates the memory for the variable and sets the initial value as defined in (1).\n",
    "\n",
    "Like with other Tensor objects, Variables are only computed when the model runs, as we can see in the following example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant(15, name = \"c\")\n",
    "x = tf.Variable(c * 5, name = \"x\")\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "session.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder\n",
    "\n",
    "TensorFlow has designated built-in structures for feeding input values. These structures are called placeholders. Placeholders can be thought of as empty variables that will be filled with data later on. We use them by first constructing our graph and only when it is executed feed them with the input data.\n",
    "\n",
    "Placeholders have three arguments we are already familiarized with: dtype for the type of data that will be inserted to them and two optional arguments — shape and name. If a shape is not fed, then the placeholder can be fed with data of any size. This is also the same as placing ‘None’ for a shape. We can also place ‘None’ for specific dimensions we are not sure about their length —for example, it is very common to use only for the rows dimension of a matrix, corresponding to the number of samples, while having the length of the columns (features) fixed. We feed the input values when running the session, just after stating what outputs we want to evaluate.\n",
    "\n",
    "Whenever we define a placeholder, we must feed it with some input values or else an exception will be thrown. The input data is given as a dictionary, where each key corresponds to a placeholder variable name, and the matching values are the data values given in the form of a list or a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31824806],\n",
       "       [ 0.45627081],\n",
       "       [ 0.13931248],\n",
       "       [ 0.01367185],\n",
       "       [ 0.69908071]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = np.random.randn(5, 10)\n",
    "w_data = np.random.randn(10, 1)\n",
    "\n",
    "X = tf.placeholder(\"float32\", shape=(5, 10))\n",
    "w = tf.placeholder(\"float32\", shape=(10, 1))\n",
    "b = tf.fill((5, 1), - 1.0)\n",
    "s = tf.sigmoid(tf.matmul(X, w) + b)\n",
    "\n",
    "session.run(s, feed_dict={X: X_data, w: w_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4000001"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.constant([3, 4, 5, 9, 11], dtype=\"float32\")\n",
    "mean = tf.reduce_mean(r)\n",
    "session.run(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (2000, 3) y shape:  (2000,) i 0.15 W:  [ 0.93581325  0.42314648  0.14204597]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_data(n, d, w = None, intercept = None, seed = None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X = np.random.rand(n, d)\n",
    "    if w is None:\n",
    "        w = np.random.random(d)\n",
    "    if intercept is None:\n",
    "        intercept = 0.15\n",
    "    noise = np.random.randn(n) * 0.1\n",
    "    y = np.dot(X, w.T) + intercept + noise\n",
    "    return X, y, intercept, w\n",
    "\n",
    "n, d = 2000, 3\n",
    "X,y,i,w = generate_data(n, d)\n",
    "print(\"X shape: \", X.shape, \"y shape: \", y.shape, \"i\", i, \"W: \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_116:0' shape=(2000, 1) dtype=float64>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.constant(X_data), tf.constant(w_real.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Dependencies\n",
    "\n",
    "In some cases, it may be wise to postpone the evaluation of an operation even though all the operations it depends on have been executed. For example, if it uses a lot of memory but its value is needed only much further in the graph, it would be best to evaluate it at the last moment to avoid needlessly occupying RAM that other operations may need. Another example is a set of operations that depend on data located outside of the device. If they all run at the same time, they may saturate the device’s communication bandwidth, and they will end up all waiting on I/O. Other operations that need to communicate data will also be blocked. It would be preferable to execute these communication-heavy operations sequentially, allowing the device to perform other operations in parallel.\n",
    "\n",
    "To postpone evaluation of some nodes, a simple solution is to add control dependencies. For example, the following code tells TensorFlow to evaluate x and y only after a and b have been evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(1.0)\n",
    "b = a + 2.0\n",
    "\n",
    "with tf.control_dependencies([a, b]):\n",
    "    x = tf.constant(3.0)\n",
    "    y = tf.constant(4.0)\n",
    "\n",
    "z = x + y\n",
    "session.run(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = tf.reduce_mean(tf.constant([3.0, 4.0, 8.0, 10.0]))\n",
    "session.run(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "W:  [ 0.93046755  0.22401114  0.90232682] i 0.15\n",
      "y_pred shape:  (1, ?) y_true shape:  (?,)\n",
      "0 [array([[ 1.64163113,  2.01862812,  0.45267594]], dtype=float32), array([[ 1.77253425]], dtype=float32)]\n",
      "10 [array([[ 0.9564029 ,  0.70228124,  0.44119522]], dtype=float32), array([[ 0.37290725]], dtype=float32)]\n",
      "20 [array([[ 0.90726435,  0.38960314,  0.67474651]], dtype=float32), array([[ 0.21698859]], dtype=float32)]\n",
      "30 [array([[ 0.91184527,  0.2841109 ,  0.79788804]], dtype=float32), array([[ 0.18504253]], dtype=float32)]\n",
      "40 [array([[ 0.91827118,  0.24455938,  0.85403699]], dtype=float32), array([[ 0.17112584]], dtype=float32)]\n",
      "50 [array([[ 0.92275876,  0.22984327,  0.8793776 ]], dtype=float32), array([[ 0.16303372]], dtype=float32)]\n",
      "60 [array([[ 0.92566574,  0.22472996,  0.89102989]], dtype=float32), array([[ 0.1580648]], dtype=float32)]\n",
      "70 [array([[ 0.92751437,  0.22322957,  0.89654613]], dtype=float32), array([[ 0.15498783]], dtype=float32)]\n",
      "80 [array([[ 0.92868036,  0.22299731,  0.89925021]], dtype=float32), array([[ 0.15307981]], dtype=float32)]\n",
      "90 [array([[ 0.92941201,  0.22314537,  0.9006269 ]], dtype=float32), array([[ 0.15189637]], dtype=float32)]\n",
      "100 [array([[ 0.92986959,  0.22335945,  0.90135491]], dtype=float32), array([[ 0.15116234]], dtype=float32)]\n",
      "110 [array([[ 0.93015492,  0.22354332,  0.90175378]], dtype=float32), array([[ 0.15070692]], dtype=float32)]\n",
      "120 [array([[ 0.9303326 ,  0.22367881,  0.90197909]], dtype=float32), array([[ 0.15042448]], dtype=float32)]\n",
      "130 [array([[ 0.93044317,  0.22377183,  0.90210956]], dtype=float32), array([[ 0.15024932]], dtype=float32)]\n",
      "140 [array([[ 0.93051189,  0.22383326,  0.90218657]], dtype=float32), array([[ 0.15014066]], dtype=float32)]\n",
      "150 [array([[ 0.93055451,  0.22387291,  0.90223283]], dtype=float32), array([[ 0.15007323]], dtype=float32)]\n",
      "160 [array([[ 0.93058103,  0.22389816,  0.90226084]], dtype=float32), array([[ 0.15003136]], dtype=float32)]\n",
      "170 [array([[ 0.93059754,  0.22391413,  0.90227789]], dtype=float32), array([[ 0.15000544]], dtype=float32)]\n",
      "180 [array([[ 0.9306078 ,  0.22392413,  0.90228832]], dtype=float32), array([[ 0.14998934]], dtype=float32)]\n",
      "190 [array([[ 0.93061417,  0.2239304 ,  0.90229481]], dtype=float32), array([[ 0.14997935]], dtype=float32)]\n",
      "200 [array([[ 0.93061811,  0.22393431,  0.90229875]], dtype=float32), array([[ 0.14997318]], dtype=float32)]\n",
      "210 [array([[ 0.93062055,  0.22393674,  0.90230119]], dtype=float32), array([[ 0.14996929]], dtype=float32)]\n",
      "220 [array([[ 0.9306221 ,  0.22393827,  0.90230274]], dtype=float32), array([[ 0.14996691]], dtype=float32)]\n",
      "230 [array([[ 0.93062299,  0.2239392 ,  0.90230364]], dtype=float32), array([[ 0.14996544]], dtype=float32)]\n",
      "240 [array([[ 0.93062359,  0.22393978,  0.90230423]], dtype=float32), array([[ 0.14996454]], dtype=float32)]\n",
      "250 [array([[ 0.93062389,  0.22394013,  0.90230453]], dtype=float32), array([[ 0.14996402]], dtype=float32)]\n",
      "260 [array([[ 0.93062413,  0.22394037,  0.90230483]], dtype=float32), array([[ 0.14996368]], dtype=float32)]\n",
      "270 [array([[ 0.93062431,  0.22394046,  0.90230501]], dtype=float32), array([[ 0.14996335]], dtype=float32)]\n",
      "280 [array([[ 0.93062437,  0.22394057,  0.90230507]], dtype=float32), array([[ 0.14996324]], dtype=float32)]\n",
      "290 [array([[ 0.93062437,  0.22394061,  0.90230507]], dtype=float32), array([[ 0.14996311]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "n, d = 2000000, 3\n",
    "X_data, y_data,i,w = generate_data(n, d)\n",
    "print(\"\\nW: \", w, \"i\", i)\n",
    "\n",
    "X = tf.placeholder(\"float32\", shape=[None, d])\n",
    "y_true = tf.placeholder(\"float32\", shape = [None])\n",
    "b = tf.Variable(tf.random_normal([1, 1]), dtype=\"float32\")\n",
    "w = tf.Variable(tf.random_normal([1, d]), dtype=\"float32\")\n",
    "y_pred = tf.matmul(w, tf.transpose(X)) + b\n",
    "\n",
    "print(\"y_pred shape: \", y_pred.get_shape(), \"y_true shape: \", y_true.get_shape())\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    for step in range(300):\n",
    "        session.run(train, {X: X_data, y_true: y_data})\n",
    "        if step % 10 == 0:\n",
    "            print(step, session.run([w, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
